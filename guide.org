
#+Author:
#+DATE:
#+PROPERTY: header-args:python :eval never-export :session
#+LATEX_CLASS: vmemoir
#+LATEX_CLASS_OPTIONS: [12pt,a4paper,twoside,openany,strict,extrafontsizes]
#+LATEX_HEADER: \usepackage[section]{placeins}
#+LATEX_HEADER: \hypersetup{hidelinks}
#+LATEX_HEADER: \PassOptionsToPackage{hyphens}{url}
#+LATEX_HEADER: \renewcommand*{\chapnumfont}{\antonioregular\HUGE}
#+LATEX_HEADER: \setsecheadstyle{\raggedright\large\bfseries}
#+LATEX_HEADER: \setsubsecheadstyle{\raggedright\bfseries\itshape}
#+LATEX_HEADER: \setcounter\secnumdepth{4}
#+LATEX_HEADER: \copypagestyle{mainmatterpage}{Ruled}
#+LATEX_HEADER: \makeevenhead{mainmatterpage}{\thepage}{}{Labour Absorption}
#+LATEX_HEADER: \makeoddhead{mainmatterpage}{\leftmark}{}{\thepage}
#+LATEX_HEADER: \makeevenfoot{mainmatterpage}{}{}{}
#+LATEX_HEADER: \makeoddfoot{mainmatterpage}{}{}{}
#+LATEX_HEADER: \copypagestyle{othermatterpage}{ruled}
#+LATEX_HEADER: \makeevenhead{othermatterpage}{\thepage}{}{\leftmark}
#+LATEX_HEADER: \makeoddhead{othermatterpage}{\leftmark}{}{\thepage}
#+LATEX_HEADER: \makeevenfoot{othermatterpage}{}{}{}
#+LATEX_HEADER: \makeoddfoot{othermatterpage}{}{}{}
#+LATEX_HEADER: \makeevenhead{headings}{\thepage}{}{\leftmark}
#+LATEX_HEADER: \makeoddhead{headings}{\rightmark}{}{\thepage}
#+LATEX_HEADER: \nouppercaseheads
#+LATEX_HEADER: \pagestyle{headings}
#+LATEX_HEADER: \emergencystretch=\maxdimen
#+LATEX_HEADER: \OnehalfSpacing
#+LATEX_HEADER: \setPagenoteSpacing{1.11}
#+LaTeX_HEADER: \setFloatSpacing{1.15}
#+LATEX_HEADER: \addtolength{\skip\footins}{10pt}
#+LATEX_HEADER: \setsecheadstyle{\raggedright\large\bfseries}
#+LATEX_HEADER: \setsubsecheadstyle{\raggedright\bfseries}
#+LaTeX_HEADER: \makechapterstyle{VZ23}{
#+LaTeX_HEADER: \renewcommand\chapternamenum{\ifanappendix {\huge\raggedright Appendix } \else \fi}
#+LaTeX_HEADER: \renewcommand\printchaptername{}
#+LaTeX_HEADER: \renewcommand\chapnamefont{\antonioregular\LARGE\raggedright}
#+LaTeX_HEADER: \renewcommand\chapnumfont{\ifanappendix \huge\raggedright \else \HUGE\raggedright \fi}
#+LaTeX_HEADER: \renewcommand\chaptitlefont{\antonioregular\LARGE\raggedright}
#+LATEX_HEADER: \usepackage{caption}
#+LATEX_HEADER: \captionsetup{justification=raggedright,singlelinecheck=false}
#+LaTeX_HEADER: \renewcommand\afterchapternum{%
#+LaTeX_HEADER: \par\nobreak\vskip\midchapskip\hrule\vskip\midchapskip}
#+LaTeX_HEADER: \renewcommand\printchapternonum{%
#+LaTeX_HEADER: \vphantom{\chapnumfont \thechapter}
#+LaTeX_HEADER: \par\nobreak\vskip\midchapskip\hrule\vskip\midchapskip}
#+LaTeX_HEADER: }
#+LATEX_HEADER: \renewcommand\cftappendixname{\appendixname~}
#+LaTeX_HEADER: \chapterstyle{VZ23}
#+LaTeX_HEADER: \addtopsmarks{ruled}{}{
#+LaTeX_HEADER:   \createmark{chapter}{left}{nonumber}{}{}
#+LaTeX_HEADER: }
#+LATEX_HEADER: \setlength\cftpartnumwidth{3em}
#+LATEX_HEADER: \captiondelim{. }
#+LATEX_HEADER: \clubpenalty=10000
#+LATEX_HEADER: \widowpenalty=10000
#+LATEX_HEADER: \hbadness=10000
#+LATEX_HEADER: \pretolerance=2000
#+LATEX_HEADER: \tolerance=2000
#+LATEX_HEADER: \emergencystretch=10pt
#+LATEX_HEADER: \hyphenpenalty=8000
#+LATEX_HEADER: \raggedbottom
#+LATEX_HEADER: \newlength{\drop}
#+LATEX_HEADER: \drop = 0.1\textheight
#+LATEX_HEADER: \usepackage{tabulary,threeparttable,longtable,float,tabularx,bookmark}
#+LATEX_HEADER: \setlength{\abovecaptionskip}{3pt}
#+LATEX_HEADER: \renewcommand{\descriptionlabel}[1]{\hspace{\labelsep}\textit{#1}}
#+LATEX_HEADER: \tracingtabularx
#+LATEX_HEADER: \renewcommand{\tabcolsep}{5pt}
#+LATEX_HEADER: \usepackage{adjustbox,xltabular}
#+LaTeX_HEADER: \setlength\midchapskip{10pt}
#+LATEX_HEADER: \usepackage[tight-spacing=true]{siunitx}
#+LATEX_HEADER: \usepackage[round-mode = places,round-precision=1]{siunitx}
#+LATEX_HEADER: \newcolumntype{C}{>{\centering\arraybackslash}X}
#+MACRO: M @@latex:\multicolumn{1}{C}{$1}@@
#+LATEX_HEADER: \renewcommand{\TPTminimum}{\linewidth}
#+LATEX_HEADER: \usepackage{comment,multirow,booktabs,lmodern,graphicx,float,wrapfig,underscore,array,url}
#+LATEX_HEADER: \newcolumntype{C}{>{\centering\arraybackslash}X}
#+LATEX_HEADER: \newcommand{\mcone}[1]{\multicolumn{1}{C}{#1}}
#+MACRO: MCONE @@latex:\mcone{$1}@@
#+LATEX_HEADER: \usepackage{etoolbox}
#+LATEX_HEADER: \appto\TPTnoteSettings{\scriptsize}
#+OPTIONS: toc:nil num:3 H:4 ^:{} broken-links:mark
#+LATEX_HEADER: \newcolumntype{H}{>{\setbox0=\hbox\bgroup}c<{\egroup}@{}}
#+LATEX_HEADER: \usepackage{pdflscape}
#+LATEX_HEADER: \usepackage{xcolor}
#+LATEX_HEADER: \usepackage[many]{tcolorbox}
#+LATEX_HEADER: \tcbuselibrary{breakable}
#+LATEX_HEADER: \NewTColorBox[auto counter,number within=chapter,list inside=box]{NewBox}{v}{%
#+LATEX_HEADER:  float*=htb,width=\textwidth,enhanced,center title,parbox=false,
#+LATEX_HEADER:  title=Box~\thetcbcounter\quad#1, % any tcolorbox options here
#+LATEX_HEADER:  }

\frontmatter
\thispagestyle{empty}


#+begin_small
\begin{titlepage}
   \begin{center}
       \vspace*{1cm}

       \textbf{Python Guide}

       \vspace{0.5cm}

        \vspace{0.8cm}

       \textbf{Prachi Bansal}


       \vfill

       \vspace{1cm}

       Data, Democracy, and Development\\
       Azim Premji University\\
       Bengaluru\\
       2023\\

   \end{center}
\end{titlepage}
#+end_small

\pagenumbering{gobble}

\newpage
\thispagestyle{empty}
\newpage
\thispagestyle{empty}
\cleartorecto

#+TOC: headlines 1
#+TOC: listings
#+TOC: tables
#+TOC: boxes


* What is Pandas and why use them?

Pandas is a popular library of python which makes working on rectangular/tabular data easy. To install pandas, use the following command:

- pip install pandas

To be sure you are not having multiple Python versions that are confusing, you should run following commands:

- python3 -m pip install pandas

* Reading data using pandas

you can use the following command:

-  a=pd.read_csv("worker.csv")//

  Note that indentation matters a lot in python. You should not writr

- pd.read_csv("worker.csv")=a or ->a//

* Investigating data using pandas

To investigate any data set, use the following commands:

+ a.head(): gives you the top 5 rows of the data (see program [[investigate]])
+ a.tail(): gives you last 5 rows
+ a.count(): gives count of non-missing observations
+ a.describe(): gives basic summary statistic for all columns
+ a.shape: tells you how many rows and columns. Please note this does not require any parenthesis because it is an argument not a method. (More about this later)



#+NAME: test
#+BEGIN_SRC python :
  def foo(x):
    if x>0:
      return x+1

    else:
      return x-1

  return foo(5)


#+end_src

#+RESULTS: test

#+NAME: test
#+begin_src python :session :results value
  import numpy as np
  a=np.array([1,2,3])
  print(type(a))

  import pandas as pd

    df = pd.DataFrame({
        "a": [1,2,3],
        "b": [4,5,6]
    })
    <<pd2org("df")>>

#+end_src


* Investigating data

#+NAME: investigate
#+BEGIN_SRC python :results value
  import pandas as pd
  a=pd.read_csv("~/acj2022/worker.csv")
  a.head()
  a.tail()
  a.describe()
  a.shape
  a.index
  a.columns
  a.dtypes
  a.info(verbose=True)
  a.size #number of elements in the file
  a.empty
  a.iat #call out for index
  a.iat[1,1]
  a.iloc[::5, :]

#+end_src

#+RESULTS: investigate


* Sorting
#+NAME: sort
#+BEGIN_SRC python :results value
  import pandas as pd
  a=pd.read_csv("~/acj2022/worker.csv",index_col=None)
  a.sort_values("wage")

  #sort rows accordinf to a particular attribute/column
  #a.sort_values("wage",ascending=False)
  a.sort_values(["wage","sex"])#note the list
  #a.sort_values(["wage","sex"],ascending=[True,False]) #each column can be sorted in a different order

#+end_src

#+RESULTS: sort

* Subset columns
#+NAME: subsetting_columns
#+BEGIN_SRC python :results value
  import pandas as pd
  a=pd.read_csv("~/acj2022/worker.csv",index_col=None)
  a["wage"]
  a[["wage","sex"]] #inner square bracket makes the list of columns to be subsetted
  #alternatively
  columns=["wage","sex"]
  a[columns]
#+end_src

#+RESULTS: subsetting_columns
#+begin_example
      wage  sex
0    120.0    1
1    224.0    1
2    132.0    1
3     75.0    1
4    111.0    2
..     ...  ...
256  120.0    1
257  437.0    1
258  417.0    1
259  120.0    1
260  320.0    1

[261 rows x 2 columns]
#+end_example

* Subset rows

#+NAME: subsetting_rows
#+BEGIN_SRC python :results value
  import pandas as pd
  a=pd.read_csv("~/acj2022/worker.csv",index_col=None)
  a["wage"]>400
  a[a["wage"]>400]
  a[a["wage"]==950]
  #subset on multiple conditions??








  a[(a["wage"]==950)&(a["sex"]==1)]
#+end_src

#+RESULTS: subsetting_rows
:     serial.no   wage  sex  edu  contract  age
: 49         50  950.0    1    4         2   47

#+NAME: is_in_method
#+BEGIN_SRC python :results value :exports results :session :hlines :colnames yes
  import pandas as pd
  a=pd.read_csv("~/acj2022/worker.csv",index_col=None)
  is_male=a["sex"].isin(["1"])
  a[is_male]
#+end_src

#+RESULTS: is_in_method
: Empty DataFrame
: Columns: [serial.no, wage, sex, edu, contract, age]
: Index: []

* New columns

+ Mutating or transforming a data frame

#+NAME: new_cols
#+BEGIN_SRC python :results value
  a["wage_new"]=a["wage"]*100
  print(a.head())
#+end_src

#+RESULTS: new_cols

* Aggregating data
+ Some summary statistics
+ Dealing with duplicates
+ Pivot tables
+ Indexing

#+NAME: summary_statistics
#+BEGIN_SRC python :results value
  a["wage"].mean()
  a["wage"].mode()
  a["wage"].median()
  a["wage"].min()
  a["wage"].max()
  a["wage"].var()
  a["wage"].std()
  a["wage"].sum()
  a["wage"].quantile()

  #can you compute the mean wage for each sex?

  a["new_wage"]=a["wage"]**2
  # .agg() method

  def pert75(column):
      return column.quantile(0.75)

  a["wage"].agg("mean")
  a[["wage","new_wage"]].agg(pert75)

  #cumulative sum
  a["wage"].cumsum()

  #IQR function
  import numpy as np
  def iqr(column):
      return column.quantile(0.75)-column.quantile(0.25)

  #print IQR of the wage column
  #print IQR of multiple columns
  #print iqr and np.median by passing both in .agg function


  ##how to work with categorical data

  .drop_duplicates method
  drop_duplicates(subset="name")
  subset=["name","breed"]

  value_counts() #gives counts

  value_counts(normalize=True) #gives proportion of the total

  # drop duplicate store and type and save as store_types
  # drop duplicate store and department and save as store_depts
  #subset the rows that are holiday weeks using is_holiday column ad drop the duplicate dates,
  #save this as holiday_dates




  a[a["sex"]==1]["wage"].mean()
  a[a["sex"]==2]["wage"].mean()

  a.groupby("sex")["wage"].mean()
  a.groupby(["sex","contract"])["wage"].mean()

  a.groupby("sex")["wage"].agg(["min", "max", "sum", "mean"])
  a.groupby(["sex","contract"])["wage"].agg(["min", "max", "sum", "mean"])
  #values: column you want to summarise, and index is the column you want to group by

  a.pivot_table(values="wage",index="sex")
  import numpy as np
  a.pivot_table(values="wage",index=["sex"],columns="contract",aggfunc=np.mean)
  a.pivot_table(values="wage",index=["sex"],columns="contract",aggfunc=np.mean,margins=True)


#+end_src

#+RESULTS: new_cols


* Dealing with Indexes

+ Note that each pandas dataframe has three components
   - A numpy array
   - A column index
   - A row index

#+NAME: indexes
#+BEGIN_SRC python :results value
  data=pd.read_csv("~/teaching2023/data/placement.csv")
  print(data)
  data.columns
  data.index

  # setting a column as index

  data_ind=data.set_index("hsc_s")
  print(data_ind)
  #index values are left aligned

  #undo what you just did
  data_ind.reset_index()

  #why index?

  # answer: makes subsetting easier
  # without indexing the code is like this
  data[data["hsc_s"].isin(["Commerce","Arts"])]

  #after setting the index you can use .loc
  data_ind=data.set_index("hsc_s")
  data_ind.loc[["Commerce","Arts"]]

  # note that values in index is not unique. Selecting arts or commerce returns multiple
  #observations for each

  # you can set multiple indexes and then subset on different levels
  #example

  data_ind1=data.set_index(["hsc_s","gender"])
  data_ind1.loc[[("Arts","M"),("Arts","F")]]
  #note the order and tuples

  data_ind1.sort_index()  #you can sort by index. By default this would sort all indexes into ascending order

  ##problems: index values are data
  ## we are moving away from tidy data because you are moving away from column formats
  ## so this is an optional way of coding

  data.loc[:,"sl_no":"degree_p"]
  # : keep everything
  data.iloc[2:5,1:4]  #final values are not included (just like lists)
#+end_src

#+RESULTS: indexes


* Visualisation

https://github.com/vikasrawal/quantitative-methods/blob/master/descriptive-statistics.org#graphical-displays-of-quantitative-information-common-pitfalls

+ Show the distribution of a numeric variable?
+ Relationship between a categorical and numeric variable
+ Changes in numeric variables over time?
+ Relationship between two numeric variables

http://localhost:8888/notebooks/matplot.ipynb


#+NAME: histogram
#+BEGIN_SRC python :results value
  import pandas as pd
  a=pd.read_csv("~/acj2022/worker.csv")
  #making a histogram
  import matplotlib.pyplot as plt
  a["wage"].hist()
  plt.show()

  #making a scatter plot
  x=a["age"]
  y=a["wage"]
  plt.scatter(x,y)
  plt.show()
#+end_src

#+Author:

+ Matplotlib gives you full control of your visualisation
+ Different ways to use matplotlib
+ We use pyplot interface

   https://www.gapminder.org/tools/#$chart-type=bubbles&url=v1


#+NAME: graph1
#+BEGIN_SRC python :results value
  import matplotlib.pyplot as plt
  fig=plt.subplots()
  plt.show()


#+end_src

Note that the plt.subplots() command created two objects: a figure and an axes.
The figure object is like a container. No data has been added yet

#+NAME: graph2
#+BEGIN_SRC python :results value
  import matplotlib.pyplot as plt
  year=[1960,1980,1990,2010]
  pop=[2.5,3.4,5.6,7.1]
  plt.plot(year,pop) #line chart
  plt.show()

  ##scatter plot
  plt.scatter(year,pop)
  plt.show()

  import pandas as pd
  b=pd.read_csv("~/teaching2023/data/gapminder.csv")
  plt.plot(b["gdp_cap"],b["life_exp"]) #line chart
  plt.show()

  ##?? does this make sense
  plt.scatter(b["gdp_cap"],b["life_exp"])
  plt.show()



#+end_src

 The two lists work as arguments. The plot function tells python what to plot and how to plot it. The show function is displaying the chart.


 histogram: to get an idea about the distribution
  How many data points in each bin?

#+NAME: graph3
#+BEGIN_SRC python :results value
   import matplotlib.pyplot as plt
   help(plt.hist)
   list1=[0,1,0.5,2,4,9,10,2,3.5,6,8,9,10,11,1.5]
   plt.hist(list1,bins=3)
   plt.show()

   #create a histogram of life expectancy data for the latest year?
   #create a histogram of life expectancy data for the first year?

 #+end_src


 10 bins default

* Customisation in Matplotlib

#+NAME: graph2
#+BEGIN_SRC python :results value
  import matplotlib.pyplot as plt
  import pandas as pd
  c=pd.read_csv("~/teaching2023/data/crimedata_suicides.csv")
  d=c[c["STATE.UT"]=="PUNJAB"]
  d=d[["Year","CAUSE","Total.Female"]]
  d=d[d["CAUSE"]=="Housewife"]
  plt.plot(d["Year"],d["Total.Female"])
  plt.xlabel("Year")
  plt.ylabel("Female Suicides")
  plt.title("Housewives Committing Suicide in Punjab")


  plt.yticks([0,30,60,90,120,150])
  plt.show()

#+end_src


#+NAME: graph3
#+BEGIN_SRC python :results value

  import matplotlib.pyplot as plt
  import pandas as pd
  import numpy as np
  np_pop=np.array(d.population)
  #=np.array(d.population)

  d = pd.read_csv("~/teaching2023/data/gapminder.csv")
  plt.scatter(x = d.gdp_cap, y = d.life_exp, s = np_pop)

  # Previous customizations
  plt.xscale('log')
  plt.xlabel('GDP per Capita [in USD]')
  plt.ylabel('Life Expectancy [in years]')
  plt.title('World Development in 2007')
  plt.xticks([1000,10000,100000], ['1k','10k','100k'])

  # Additional customizations
  plt.text(1550, 71, 'India')
  plt.text(5700, 80, 'China')

  plt.show()









  np_pop2 = np_pop*2
  plt.scatter(gapminder_data.gdp_cap, gapminder_data.life_exp, s = np_pop2)
  plt.grid(True)
  plt.xscale('log')
  plt.xlabel('GDP per Capita [in USD]')
  plt.ylabel('Life Expectancy [in years]')
  plt.title('World Development in 2007')
  plt.xticks([1000, 10000, 100000],['1k', '10k', '100k'])
  plt.show()

#+END_SRC
